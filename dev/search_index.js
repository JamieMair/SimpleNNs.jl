var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [SimpleNNs, SimpleNNs.GPU]","category":"page"},{"location":"api/#SimpleNNs.Conv-Union{Tuple{N}, Tuple{Tuple{Vararg{Int64, N}}, Int64}} where N","page":"API","title":"SimpleNNs.Conv","text":"Conv(kernel_size::NTuple{N, Int}, out_channels::Int; kwargs...)\n\nA convolutional layer with a given kernel size and specified number of output channels.\n\nThis can automatically infer the number of input channels based on the preceeding layers.\n\nKeyword Arguments\n\nuse_bias (default: Val(true)) - Whether or not to add a bias vector to the output. Wrapped in a Val for optimisation.\nactivation_fn (default: identity) - A custom activation function. Note that not all functions are supported by backpropagation.\nparameter_type (default: Val(Float32)) - The datatype to use for the parameters, wrapped in a Val type.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.Dense-Tuple{Integer}","page":"API","title":"SimpleNNs.Dense","text":"Dense(outputs::Integer; kwargs...)\n\nA representation of a dense layer. By default this can be constructed by  specifying the desired number of outputs. The input size can be inferred from the rest of the chain when constructing a model.\n\nKeyword Arguments\n\nuse_bias (default: Val(true)) - Whether or not to add a bias vector to the output. Wrapped in a Val for optimisation.\nactivation_fn (default: identity) - A custom activation function. Note that not all functions are supported by backpropagation.\nparameter_type (default: Val(Float32)) - The datatype to use for the parameters, wrapped in a Val type.\ninputs (default: Infer()) - Specify the number of inputs, or infer them from the rest of the model.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.Flatten","page":"API","title":"SimpleNNs.Flatten","text":"Flatten()\n\nFlatten the dimensions of the preceeding layer, leaving the batch dimension unaffected. The output should be (k x n) where k is the product of the non-batch dimensions of the previous layer.\n\n\n\n\n\n","category":"type"},{"location":"api/#SimpleNNs.LogitCrossEntropyLoss","page":"API","title":"SimpleNNs.LogitCrossEntropyLoss","text":"LogitCrossEntropyLoss(targets, num_classes::Int)\n\nExpects the targets in a single vector containg class labels, which have to be between 1 and num_classes inclusive.\n\n\n\n\n\n","category":"type"},{"location":"api/#SimpleNNs.MSELoss","page":"API","title":"SimpleNNs.MSELoss","text":"MSELoss(targets)\n\nExpects the targets in the form (K x N) where K is the output dimension (usually 1) and N is the batch size.\n\n\n\n\n\n","category":"type"},{"location":"api/#SimpleNNs.MaxPool-Union{Tuple{Tuple{Vararg{Int64, N}}}, Tuple{N}} where N","page":"API","title":"SimpleNNs.MaxPool","text":"MaxPool(pool_size::NTuple{N, Int}; kwargs...)\n\nA convolutional max-pool layer with a given kernel size.\n\nThis can automatically infer the necessary sizes if specified.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.Static-Tuple{Union{Int64, Tuple{Vararg{T, N}} where {N, T}}}","page":"API","title":"SimpleNNs.Static","text":"Static(inputs::Union{Int, NTuple}; kwargs...)\n\nUsed for specifying the input type to a neural network. inputs should  be a single integer for a dense network, representing the number of  features. For a image network, inputs can be a tuple specifying the size of the images in the form (WIDTH, HEIGHT, CHANNELS).\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.activation_gradient_fn-Union{Tuple{Dense{DT, K, T}}, Tuple{T}, Tuple{K}, Tuple{DT}} where {DT, K, T}","page":"API","title":"SimpleNNs.activation_gradient_fn","text":"Dertivatives are used to backpropagate the gradients of the layer outputs back to the activations of that layer. To save space, these are calculated exclusively using the outputs of the layer. Instead of functions written as dy/dx=f(x), we  instead write dy/dx = g(y). This can be done for the 3 major functions.\n\nWhenever y is used below, assume this is a function of the output, not the input.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.backprop!-NTuple{5, Any}","page":"API","title":"SimpleNNs.backprop!","text":"backprop!(partials_buffer, gradient_buffer, inputs, outputs, layer)\n\nBackpropagates the partial gradients of the outputs of the current layer into the parameters of the current layer. partial_buffers is used as a buffer for the gradients of the output of this layer. gradient_buffer should be  filled up with the gradients of the parameters of the current layer, using the chain rule. inputs is the array fed into the layer and outputs is the output of this layer in the forward pass. layer is the struct containing information about the layer.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.chain-Tuple","page":"API","title":"SimpleNNs.chain","text":"chain(layers...)\n\nCombines the given layer definitions into a single model and propagates the layer sizes through the network.\n\nThe first layer must always be a Static layer which specifies the feature size. If this is a simple fully connection network, then the first layer should be Static(nf) where nf is the number of features in your input matrix. Do not specify the batch size in this static input.\n\nThe default datatype for most layers is Float32, but this may be changed. The parameters of the entire model must be of the same datatype. This function will create a flat parameter vector for the model which can be accessed using the parameters function.\n\nExamples\n\nA simple dense, fully-connected, neural network which has 3 input features:\n\nmodel = chain(\n    Static(3),\n    Dense(10, activation_fn=tanh),\n    Dense(10, activation_fn=sigmoid),\n    Dense(1, activation_fn=identity),\n);\n\nAn example convolutional neural network:\n\n# Image size is (WIDTH, HEIGHT, CHANNELS)\nimg_size = (28, 28, 1)\nmodel = chain(\n    Static(img_size),\n    Conv((5,5), 16; activation_fn=relu),\n    MaxPool((2,2)),\n    Conv((3,3), 8; activation_fn=relu),\n    MaxPool((4,4)),\n    Flatten(),\n    Dense(10, activation_fn=identity)\n)\n\nSee also Static, Dense, Conv, MaxPool, Flatten and preallocate.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.get_outputs-Tuple{SimpleNNs.ForwardPassCache}","page":"API","title":"SimpleNNs.get_outputs","text":"get_outputs(cache::ForwardPassCache)\n\nGets the last output from the forward pass buffer.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.gradients-Tuple{SimpleNNs.BackpropagationCache}","page":"API","title":"SimpleNNs.gradients","text":"gradients(cache::BackpropagationCache)\n\nExtracts the gradient array from the backwards pass buffer, filled from use of the backprop! function.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.parameters-Tuple{SimpleNNs.Model}","page":"API","title":"SimpleNNs.parameters","text":"parameters(model::Model)\n\nReturns the array used to store the parameters of the model.\n\nModifying this array will change the parameters of the model.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.preallocate-Tuple{SimpleNNs.Model, Integer}","page":"API","title":"SimpleNNs.preallocate","text":"preallocate(model::Model, batch_size::Integer)\n\nCreates a buffer to store the intermediate layer outputs of a forward pass, along with the input.\n\nThe inputs can be set using set_inputs! and the outputs can be retrieved using get_outputs.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.preallocate_grads-Tuple{SimpleNNs.Model, Integer}","page":"API","title":"SimpleNNs.preallocate_grads","text":"preallocategrads(model::Model, batchsize::Integer)\n\nCreates a buffer to store the intermediate arrays needed for backpropagation.\n\nThe gradients can be retrieved from the buffer using gradients on the buffer.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.pullback!-Tuple{Any, Any, SimpleNNs.AbstractLayer}","page":"API","title":"SimpleNNs.pullback!","text":"pullback!(input_partials, output_partials, layer)\n\nHere, we complete the backpropagation of the partial gradients to the inputs of the current layer. This should be called after backprop!. This method will fill the input_partials buffer with partial gradients calculated via the chain rule from the gradients of the partials from this layer's output.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.set_inputs!-Tuple{SimpleNNs.ForwardPassCache, Any}","page":"API","title":"SimpleNNs.set_inputs!","text":"set_inputs!(cache::ForwardPassCache, inputs)\n\nSets the input array in the forward pass cache.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimpleNNs.GPU.gpu-Tuple{Any}","page":"API","title":"SimpleNNs.GPU.gpu","text":"gpu(x)\n\nCreates a copy of x on the GPU, using CUDA. Works for models created with chain or plain arrays.\n\n\n\n\n\n","category":"method"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Firstly, you can add this package directly using the URL:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"import Pkg; Pkg.add(\"https://github.com/JamieMair/SimpleNNs.jl\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Note: This package has plans to be registered and should be available with ] add SimpleNNs in the future.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Once the package is installed, go ahead and load the package.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using SimpleNNs\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To start with, let's create a simple test dataset:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"batch_size = 256\nx = collect(LinRange(0, 2*pi, batch_size)')\ny = sin.(x)\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Note that we use the adjoint ' so that the last dimension is the batch dimension.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can now create our small neural network to fit a curve that maps from x to y. The syntax will be familiar to users of Flux.jl or SimpleChains.jl.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"model = chain(\n    Static(1),\n    Dense(10, activation_fn=tanh),\n    Dense(10, activation_fn=sigmoid),\n    Dense(1, activation_fn=identity),\n);\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Here, we specify the expected feature size of the input, leaving out the batch dimension.","category":"page"},{"location":"getting_started/#Inference-(Forward-Pass)","page":"Getting Started","title":"Inference (Forward-Pass)","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To run inference with this model, we first need to preallocate a buffer to store the intermediate forward pass values. This preallocation is by design, so that memory is only allocated once at the beginning of training.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"forward_buffer = preallocate(model, batch_size);\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"This buffer also contains the input to the neural network. We can set the inputs to the neural network via","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"set_inputs!(forward_buffer, x);\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The above function can be used to set the new inputs at each epoch.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can access the flat parameter vector of the model via parameters(model) to initialise the weights of the network, i.e.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Random\nRandom.seed!(1234)\nparams = parameters(model);\nrandn!(params);\nparams .*= 0.1;\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can run inference with","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"forward!(forward_buffer, model);\nyhat = get_outputs(forward_buffer);\nnothing # hide","category":"page"},{"location":"getting_started/#Training-(Backward-Pass)","page":"Getting Started","title":"Training (Backward-Pass)","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can specify a mean-squared error loss via","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"loss = MSELoss(y);\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"and preallocate the buffer used for calculating the gradients via back-propagation:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"gradient_buffer = preallocate_grads(model, batch_size);\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Now we have all the ingredients we need to write a simple training script, making use of Optimisers.jl.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"import Optimisers\n\nlr = 0.01\nopt = Optimisers.setup(Optimisers.Adam(lr), params)\nepochs = 1000\nlosses = zeros(Float32, epochs)\nfor i in 1:epochs\n    forward!(forward_buffer, model)\n    losses[i] = backprop!(gradient_buffer, forward_buffer, model, loss)\n    grads = gradients(gradient_buffer) # extract the gradient vector\n    # Apply the optimiser\n    Optimisers.update!(opt, params, grads)\nend\n\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can plot the losses over time, for example using Plots.jl:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Plots\nusing PlotThemes # hide\ntheme(:dark) # hide\nplot(losses, xlabel=\"Epochs\", ylabel=\"MSE Loss\", lw=2, label=nothing)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Finally, we can run one final forward pass to get the predictions","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"forward!(forward_buffer, model);\nyhat = get_outputs(forward_buffer);\nnothing # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"and then plot the predictions","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Plots\nplt = plot(x', y', linestyle=:solid, label=\"Original\", lw=2);\nplot!(plt, x', yhat', linestyle=:dashdot, label=\"Prediction\", lw=2);\nxlabel!(\"x\")\nylabel!(\"y\")\nplt","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To see an example using convolution layers and GPU training, see the MNIST training example.","category":"page"},{"location":"function_index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"function_index/","page":"Index","title":"Index","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = SimpleNNs","category":"page"},{"location":"#SimpleNNs","page":"Home","title":"SimpleNNs","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"SimpleNNs.jl is heavily inspired by SimpleChains.jl, which showed that there is space for micro-optimisations to be very important for small neural networks (see the blog post). This project aims to expand upon SimpleChains.jl by introducing both CPU and GPU support.","category":"page"},{"location":"","page":"Home","title":"Home","text":"As the name suggests, this is not a fully featured neural network library, and most notably, it does not include auto-differentiation capabilities. The goals of this package are the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"To build simple neural network architectures, whose parameters are represented as a simple flat vector.\nTo be able to train and run these neural networks with pre-allocated buffers to avoid memory allocations.\nTo be executable on either the GPU or the CPU.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Currently, there is full support for dense layers with the traditional activation functions: textReLU, tanh (hyperbolic tangent) and sigma (logistic sigmoid). Custom loss functions will work on forward passes, but the gradient must be overloaded as detailed in another page of this documentation. Convolutional layers are also supported, with some limitations on parameters such as stride.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Head over to the Getting Started page to see how to use this package.","category":"page"},{"location":"#Documentation-Outline","page":"Home","title":"Documentation Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"getting_started.md\",\n    \"mnist.md\",\n    \"api.md\",\n    \"function_index.md\"\n]\nDepth = 2","category":"page"},{"location":"mnist/#MNIST","page":"MNIST","title":"MNIST","text":"","category":"section"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"In this example, we will train a small neural network to classify the MNIST digit dataset. We will use MLDatasets to load our dataset.","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"using MLDatasets\ndataset = MNIST(:train);\nimages, labels = dataset[:];\n# reshape images array to add in a channel\nimages = reshape(images, size(images, 1), size(images, 2), 1, size(images, 3));\n# Make our labels from 1 to 10 instead\nlabels .+= 1;\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"If you have an NVIDIA GPU, you can modify the code below to set use_gpu equal to true.","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"using SimpleNNs\nimport SimpleNNs.GPU: gpu\nuse_gpu = true;\nto_device = use_gpu ? gpu : identity;\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"We can use this function to put our data onto the GPU, using the pipe operator:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"images = images |> to_device;\nlabels = labels |> to_device;\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"Next, we can create our model:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"img_size = size(images)[1:end-1]\nmodel = chain(\n    Static(img_size),\n    Conv((5,5), 16; activation_fn=relu),\n    MaxPool((2,2)),\n    Conv((3,3), 8; activation_fn=relu),\n    MaxPool((4,4)),\n    Flatten(),\n    Dense(10, activation_fn=identity)\n) |> to_device;\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"For training, we will use stochastic gradient descent (with the ADAM optimiser), with a batch size of 32. We need to preallocate our buffers, as below:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"batch_size = 32;\nforward_buffer = preallocate(model, batch_size);\ngradient_buffer = preallocate_grads(model, batch_size);\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"Now, we write our training loop:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"using Random\nRandom.seed!(1234)\nparams = parameters(model);\nrandn!(params)\nparams .*= 0.05\nimport Optimisers\nlr = 0.01;\nopt = Optimisers.setup(Optimisers.Adam(lr), params);\nepochs = 1000;\nlosses = zeros(Float32, epochs);\ntraining_indices = collect(1:length(labels));\n\nfor i in 1:epochs\n    # Select a random batch\n    Random.shuffle!(training_indices)\n    batch_indices = view(training_indices, 1:batch_size)\n    # Set the inputs of the forward buffer to this minibatch\n    set_inputs!(forward_buffer, view(images, :, :, :, batch_indices));\n    # Create a loss function that wraps the current minibatch labels\n    loss = LogitCrossEntropyLoss(view(labels, batch_indices), 10);\n\n\n    forward!(forward_buffer, model)\n    losses[i] = backprop!(gradient_buffer, forward_buffer, model, loss)\n    grads = gradients(gradient_buffer) # extract the gradient vector\n    # Apply the optimiser\n    Optimisers.update!(opt, params, grads)\nend\n\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"We can plot the losses over time, for example using Plots.jl:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"using Plots\nusing PlotThemes # hide\ntheme(:dark) # hide\nplot(losses, xlabel=\"Epochs\", ylabel=\"Cross Entropy Loss\", lw=2, label=nothing)","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"Finally, we can test the accuracy of the model by loading the test set:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"dataset = MNIST(:test);\ntest_images, test_labels = dataset[:];\n# reshape images array to add in a channel\ntest_images = reshape(test_images, size(test_images, 1), size(test_images, 2), 1, size(test_images, 3));\n# Make our labels from 1 to 10 instead\ntest_labels .+= 1;\ntest_images = test_images |> to_device;\ntest_labels = test_labels |> to_device;\n","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"Now, we create a forward buffer for the test images:","category":"page"},{"location":"mnist/","page":"MNIST","title":"MNIST","text":"test_forward_buffer = preallocate(model, length(test_labels));\nset_inputs!(test_forward_buffer, test_images);\nforward!(test_forward_buffer, model);\nlogits = get_outputs(test_forward_buffer);\npredictions = reshape([i[1] for i in Array(argmax(logits, dims=1))], :) |> to_device;\naccuracy = sum(predictions .== test_labels) / length(test_labels) * 100\n@show accuracy","category":"page"}]
}
